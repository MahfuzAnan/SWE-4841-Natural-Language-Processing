{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e45965b2aa44e32ac2cc019b2fa57a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504b9c4e13d9495c915d385d132960a5",
              "IPY_MODEL_372937e26b4e4f9eb49b391d91a70e97",
              "IPY_MODEL_9768bcf20a0e496e94b59ae8946d1d42"
            ],
            "layout": "IPY_MODEL_bb56f242ebc44c75a05a522508825ec3"
          }
        },
        "504b9c4e13d9495c915d385d132960a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10b6f6ceeaeb45c3be36419973aa22ca",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd2ba008fbb4a7a8a1ca623ddafb9d1",
            "value": "Embedding batches:  23%"
          }
        },
        "372937e26b4e4f9eb49b391d91a70e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b885e1a01b44b14b5a3ac48315d8da4",
            "max": 7909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aea96ef060d445fb6873ffe2681a657",
            "value": 1783
          }
        },
        "9768bcf20a0e496e94b59ae8946d1d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad32bc934c204b19a8dd9a21de103e04",
            "placeholder": "​",
            "style": "IPY_MODEL_484ae71619f84f768c2bfa33bf56654e",
            "value": " 1783/7909 [13:45&lt;52:12,  1.96it/s]"
          }
        },
        "bb56f242ebc44c75a05a522508825ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b6f6ceeaeb45c3be36419973aa22ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd2ba008fbb4a7a8a1ca623ddafb9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b885e1a01b44b14b5a3ac48315d8da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aea96ef060d445fb6873ffe2681a657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad32bc934c204b19a8dd9a21de103e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484ae71619f84f768c2bfa33bf56654e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load & inspect Parquet dataset (Colab)\n",
        "# Run in Google Colab.\n",
        "\n",
        "# 1) Ensure parquet support\n",
        "!pip install -q pyarrow\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "from IPython.display import display\n",
        "\n",
        "# ---------- USER ACTION: choose one of these ways to provide the file ----------\n",
        "# Option A — upload from your local machine (uncomment to use)\n",
        "# uploaded = files.upload()                      # a file picker will appear\n",
        "# file_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Option B — mount Google Drive and use path on Drive (uncomment to use)\n",
        "# drive.mount('/content/drive')\n",
        "# file_path = '/content/drive/MyDrive/path/to/your_dataset.parquet'\n",
        "\n",
        "# Option C — if you already uploaded the file earlier or it is in working dir:\n",
        "# file_path = 'your_dataset.parquet'\n",
        "\n",
        "# Set file_path variable now (edit as needed)\n",
        "file_path = '/content/drive/MyDrive/Dataset/BaitBuster-Bangla_253070_18c_HL10k_AIL.parquet'   # <- CHANGE this to your filename / path\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Try to load the parquet file\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"File not found at: {file_path}. \\\n",
        "Either upload the file (files.upload()) or mount Drive and set file_path correctly.\")\n",
        "\n",
        "df = pd.read_parquet(file_path)\n",
        "print(f\"Loaded DataFrame: shape = {df.shape}\\n\")\n",
        "\n",
        "# Quick peek\n",
        "print(\"Columns:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# Which expected text & label columns are present?\n",
        "text_cols = ['title', 'title_debiased', 'description', 'description_debiased']\n",
        "label_cols = ['auto_labeled', 'human_labeled', 'ai_labeled']\n",
        "\n",
        "present_text = [c for c in text_cols if c in df.columns]\n",
        "present_labels = [c for c in label_cols if c in df.columns]\n",
        "\n",
        "print(f\"\\nText columns present: {present_text}\")\n",
        "print(f\"Label columns present: {present_labels}\\n\")\n",
        "\n",
        "# Basic null / length stats for text columns\n",
        "print(\"Text columns: non-null count and sample lengths (first 3 non-null):\")\n",
        "for c in present_text:\n",
        "    non_null = df[c].notna().sum()\n",
        "    sample_lens = df[c].dropna().astype(str).map(len).sort_values().unique()[:3].tolist()\n",
        "    print(f\"  - {c}: {non_null} non-null, sample length values (smallest) {sample_lens}\")\n",
        "\n",
        "# Inspect each label column: dtype, unique values, counts\n",
        "def inspect_label(col):\n",
        "    print(f\"\\n--- Inspecting label column: {col} ---\")\n",
        "    ser = df[col]\n",
        "    print(\"dtype:\", ser.dtype)\n",
        "    # Show up to first 20 unique values\n",
        "    uniques = pd.Series(ser.dropna().unique()).head(20).tolist()\n",
        "    print(\"sample unique values (up to 20):\", uniques)\n",
        "    try:\n",
        "        print(\"value counts (top 10):\")\n",
        "        print(ser.value_counts(dropna=False).head(10))\n",
        "    except Exception as e:\n",
        "        print(\"Could not compute value_counts:\", e)\n",
        "    if pd.api.types.is_numeric_dtype(ser):\n",
        "        print(\"numeric summary:\")\n",
        "        print(ser.describe())\n",
        "\n",
        "for c in present_labels:\n",
        "    inspect_label(c)\n",
        "\n",
        "# If multiple label columns present, show cross-tab / agreement overview\n",
        "if len(present_labels) >= 2:\n",
        "    print(\"\\nLabel cross-tabs (pairwise):\")\n",
        "    for i in range(len(present_labels)):\n",
        "        for j in range(i+1, len(present_labels)):\n",
        "            a = present_labels[i]; b = present_labels[j]\n",
        "            print(f\"\\nCross-tab: {a} vs {b}\")\n",
        "            try:\n",
        "                print(pd.crosstab(df[a], df[b], margins=True))\n",
        "            except Exception as e:\n",
        "                print(\"Could not produce crosstab:\", e)\n",
        "\n",
        "# Create a small sample CSV (optional) so you can attach it quickly if needed\n",
        "sample_csv = \"sample_first_200.csv\"\n",
        "df.head(200).to_csv(sample_csv, index=False)\n",
        "print(f\"\\nSaved first 200 rows to {sample_csv} (you can download from Colab sidebar).\")\n",
        "\n",
        "print(\"\\n\\n===== DONE: paste the printed outputs (or upload the sample CSV) and I'll provide the next step =====\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8OH8gNZQhNMA",
        "outputId": "271696c4-6611-48fa-bde6-ccb130f71f29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded DataFrame: shape = (253070, 18)\n",
            "\n",
            "Columns:\n",
            "['channel_id', 'channel_name', 'channel_url', 'video_id', 'publishedAt', 'title', 'title_debiased', 'description', 'description_debiased', 'url', 'viewCount', 'commentCount', 'likeCount', 'dislikeCount', 'thumbnail', 'auto_labeled', 'human_labeled', 'ai_labeled']\n",
            "\n",
            "First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 channel_id       channel_name  \\\n",
              "0  UCw4gfo5oaGPkHwarenuewAg  Ruposhi Bangla Tv   \n",
              "1  UCw4gfo5oaGPkHwarenuewAg  Ruposhi Bangla Tv   \n",
              "2  UCw4gfo5oaGPkHwarenuewAg  Ruposhi Bangla Tv   \n",
              "3  UCw4gfo5oaGPkHwarenuewAg  Ruposhi Bangla Tv   \n",
              "4  UCw4gfo5oaGPkHwarenuewAg  Ruposhi Bangla Tv   \n",
              "\n",
              "                                         channel_url     video_id  \\\n",
              "0  https://www.youtube.com/c/RuposhiBanglaTvtopvi...  J9xErXLh3bo   \n",
              "1  https://www.youtube.com/c/RuposhiBanglaTvtopvi...  HPa6mRwjUg8   \n",
              "2  https://www.youtube.com/c/RuposhiBanglaTvtopvi...  bwkR5p0VY7Y   \n",
              "3  https://www.youtube.com/c/RuposhiBanglaTvtopvi...  rwxsUpXAozk   \n",
              "4  https://www.youtube.com/c/RuposhiBanglaTvtopvi...  hyBKq5IBras   \n",
              "\n",
              "            publishedAt                                              title  \\\n",
              "0  2021-08-17T08:59:13Z  এইমাত্র! মসজিদে নামাজরত অবস্থায় তিন বৃদ্ধকে পি...   \n",
              "1  2021-08-17T04:19:08Z  ১০ বছরের সন্তান ফেলে আ,লীগ নেতার সাথে পালিয়ে গ...   \n",
              "2  2021-08-16T15:18:16Z  এই মাত্র পাওয়া খবর! ৫ বছরের জেল হচ্ছে পরীমনির!...   \n",
              "3  2021-08-16T08:11:47Z  ছি ছি! ভাগিনার সাথে পরকীয়ার সময় হাতেনাতে ধরা খ...   \n",
              "4  2021-08-16T03:45:16Z  হায়রে পরীমনি! কারাগারে গিয়েও ভালো হলোনা! কারাগ...   \n",
              "\n",
              "                                      title_debiased  \\\n",
              "0  এইমাত্র! মসজিদে নামাজরত অবস্থায় তিন বৃদ্ধকে পি...   \n",
              "1  ১০ বছরের সন্তান ফেলে আ,লীগ নেতার সাথে পালিয়ে গ...   \n",
              "2  এই মাত্র পাওয়া খবর! ৫ বছরের জেল হচ্ছে পরীমনির!...   \n",
              "3  ছি ছি! ভাগিনার সাথে পরকীয়ার সময় হাতেনাতে ধরা খ...   \n",
              "4  হায়রে পরীমনি! কারাগারে গিয়েও ভালো হলোনা! কারাগ...   \n",
              "\n",
              "                                         description  \\\n",
              "0  ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...   \n",
              "1  ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...   \n",
              "2  ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...   \n",
              "3  ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...   \n",
              "4  ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...   \n",
              "\n",
              "                                description_debiased  \\\n",
              "0  ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...   \n",
              "1  ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...   \n",
              "2  ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...   \n",
              "3  ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...   \n",
              "4  ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...   \n",
              "\n",
              "                                           url  viewCount  commentCount  \\\n",
              "0  https://www.youtube.com/watch?v=J9xErXLh3bo      12743            45   \n",
              "1  https://www.youtube.com/watch?v=HPa6mRwjUg8      22440            10   \n",
              "2  https://www.youtube.com/watch?v=bwkR5p0VY7Y      46416            53   \n",
              "3  https://www.youtube.com/watch?v=rwxsUpXAozk      50177            23   \n",
              "4  https://www.youtube.com/watch?v=hyBKq5IBras     114242            59   \n",
              "\n",
              "   likeCount  dislikeCount                                       thumbnail  \\\n",
              "0        536            35  https://i.ytimg.com/vi/J9xErXLh3bo/default.jpg   \n",
              "1        362            20  https://i.ytimg.com/vi/HPa6mRwjUg8/default.jpg   \n",
              "2        677            57  https://i.ytimg.com/vi/bwkR5p0VY7Y/default.jpg   \n",
              "3        558            40  https://i.ytimg.com/vi/rwxsUpXAozk/default.jpg   \n",
              "4       1352           122  https://i.ytimg.com/vi/hyBKq5IBras/default.jpg   \n",
              "\n",
              "  auto_labeled human_labeled ai_labeled  \n",
              "0    Clickbait     Clickbait  Clickbait  \n",
              "1    Clickbait     Clickbait  Clickbait  \n",
              "2    Clickbait     Clickbait  Clickbait  \n",
              "3    Clickbait     Clickbait  Clickbait  \n",
              "4    Clickbait     Clickbait  Clickbait  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d757338-a2b2-4661-ae93-efde8d99fb90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel_id</th>\n",
              "      <th>channel_name</th>\n",
              "      <th>channel_url</th>\n",
              "      <th>video_id</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>title</th>\n",
              "      <th>title_debiased</th>\n",
              "      <th>description</th>\n",
              "      <th>description_debiased</th>\n",
              "      <th>url</th>\n",
              "      <th>viewCount</th>\n",
              "      <th>commentCount</th>\n",
              "      <th>likeCount</th>\n",
              "      <th>dislikeCount</th>\n",
              "      <th>thumbnail</th>\n",
              "      <th>auto_labeled</th>\n",
              "      <th>human_labeled</th>\n",
              "      <th>ai_labeled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UCw4gfo5oaGPkHwarenuewAg</td>\n",
              "      <td>Ruposhi Bangla Tv</td>\n",
              "      <td>https://www.youtube.com/c/RuposhiBanglaTvtopvi...</td>\n",
              "      <td>J9xErXLh3bo</td>\n",
              "      <td>2021-08-17T08:59:13Z</td>\n",
              "      <td>এইমাত্র! মসজিদে নামাজরত অবস্থায় তিন বৃদ্ধকে পি...</td>\n",
              "      <td>এইমাত্র! মসজিদে নামাজরত অবস্থায় তিন বৃদ্ধকে পি...</td>\n",
              "      <td>ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...</td>\n",
              "      <td>ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...</td>\n",
              "      <td>https://www.youtube.com/watch?v=J9xErXLh3bo</td>\n",
              "      <td>12743</td>\n",
              "      <td>45</td>\n",
              "      <td>536</td>\n",
              "      <td>35</td>\n",
              "      <td>https://i.ytimg.com/vi/J9xErXLh3bo/default.jpg</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UCw4gfo5oaGPkHwarenuewAg</td>\n",
              "      <td>Ruposhi Bangla Tv</td>\n",
              "      <td>https://www.youtube.com/c/RuposhiBanglaTvtopvi...</td>\n",
              "      <td>HPa6mRwjUg8</td>\n",
              "      <td>2021-08-17T04:19:08Z</td>\n",
              "      <td>১০ বছরের সন্তান ফেলে আ,লীগ নেতার সাথে পালিয়ে গ...</td>\n",
              "      <td>১০ বছরের সন্তান ফেলে আ,লীগ নেতার সাথে পালিয়ে গ...</td>\n",
              "      <td>ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...</td>\n",
              "      <td>ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...</td>\n",
              "      <td>https://www.youtube.com/watch?v=HPa6mRwjUg8</td>\n",
              "      <td>22440</td>\n",
              "      <td>10</td>\n",
              "      <td>362</td>\n",
              "      <td>20</td>\n",
              "      <td>https://i.ytimg.com/vi/HPa6mRwjUg8/default.jpg</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UCw4gfo5oaGPkHwarenuewAg</td>\n",
              "      <td>Ruposhi Bangla Tv</td>\n",
              "      <td>https://www.youtube.com/c/RuposhiBanglaTvtopvi...</td>\n",
              "      <td>bwkR5p0VY7Y</td>\n",
              "      <td>2021-08-16T15:18:16Z</td>\n",
              "      <td>এই মাত্র পাওয়া খবর! ৫ বছরের জেল হচ্ছে পরীমনির!...</td>\n",
              "      <td>এই মাত্র পাওয়া খবর! ৫ বছরের জেল হচ্ছে পরীমনির!...</td>\n",
              "      <td>ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...</td>\n",
              "      <td>ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...</td>\n",
              "      <td>https://www.youtube.com/watch?v=bwkR5p0VY7Y</td>\n",
              "      <td>46416</td>\n",
              "      <td>53</td>\n",
              "      <td>677</td>\n",
              "      <td>57</td>\n",
              "      <td>https://i.ytimg.com/vi/bwkR5p0VY7Y/default.jpg</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UCw4gfo5oaGPkHwarenuewAg</td>\n",
              "      <td>Ruposhi Bangla Tv</td>\n",
              "      <td>https://www.youtube.com/c/RuposhiBanglaTvtopvi...</td>\n",
              "      <td>rwxsUpXAozk</td>\n",
              "      <td>2021-08-16T08:11:47Z</td>\n",
              "      <td>ছি ছি! ভাগিনার সাথে পরকীয়ার সময় হাতেনাতে ধরা খ...</td>\n",
              "      <td>ছি ছি! ভাগিনার সাথে পরকীয়ার সময় হাতেনাতে ধরা খ...</td>\n",
              "      <td>ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...</td>\n",
              "      <td>ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...</td>\n",
              "      <td>https://www.youtube.com/watch?v=rwxsUpXAozk</td>\n",
              "      <td>50177</td>\n",
              "      <td>23</td>\n",
              "      <td>558</td>\n",
              "      <td>40</td>\n",
              "      <td>https://i.ytimg.com/vi/rwxsUpXAozk/default.jpg</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UCw4gfo5oaGPkHwarenuewAg</td>\n",
              "      <td>Ruposhi Bangla Tv</td>\n",
              "      <td>https://www.youtube.com/c/RuposhiBanglaTvtopvi...</td>\n",
              "      <td>hyBKq5IBras</td>\n",
              "      <td>2021-08-16T03:45:16Z</td>\n",
              "      <td>হায়রে পরীমনি! কারাগারে গিয়েও ভালো হলোনা! কারাগ...</td>\n",
              "      <td>হায়রে পরীমনি! কারাগারে গিয়েও ভালো হলোনা! কারাগ...</td>\n",
              "      <td>ভিডিওটি ভাল লাগলে লাইক দিন \\r\\nও সবাইকে দেখার ...</td>\n",
              "      <td>ভিডিওটি লাগলে লাইক দিন ও সবাইকে দেখার সুযোগ কর...</td>\n",
              "      <td>https://www.youtube.com/watch?v=hyBKq5IBras</td>\n",
              "      <td>114242</td>\n",
              "      <td>59</td>\n",
              "      <td>1352</td>\n",
              "      <td>122</td>\n",
              "      <td>https://i.ytimg.com/vi/hyBKq5IBras/default.jpg</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "      <td>Clickbait</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d757338-a2b2-4661-ae93-efde8d99fb90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d757338-a2b2-4661-ae93-efde8d99fb90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d757338-a2b2-4661-ae93-efde8d99fb90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-09657334-89b3-4149-83c3-0c72cad38019\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09657334-89b3-4149-83c3-0c72cad38019')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-09657334-89b3-4149-83c3-0c72cad38019 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\\\n===== DONE: paste the printed outputs (or upload the sample CSV) and I'll provide the next step =====\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"channel_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"UCw4gfo5oaGPkHwarenuewAg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channel_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ruposhi Bangla Tv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channel_url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://www.youtube.com/c/RuposhiBanglaTvtopvideos/videos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"HPa6mRwjUg8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publishedAt\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2021-08-17T04:19:08Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u09e7\\u09e6 \\u09ac\\u099b\\u09b0\\u09c7\\u09b0 \\u09b8\\u09a8\\u09cd\\u09a4\\u09be\\u09a8 \\u09ab\\u09c7\\u09b2\\u09c7 \\u0986,\\u09b2\\u09c0\\u0997 \\u09a8\\u09c7\\u09a4\\u09be\\u09b0 \\u09b8\\u09be\\u09a5\\u09c7 \\u09aa\\u09be\\u09b2\\u09bf\\u09df\\u09c7 \\u0997\\u09c7\\u09b2 \\u098f\\u09ae\\u09aa\\u09bf\\u09b0 \\u09ae\\u09c7\\u09df\\u09c7! \\u09b8\\u09ac \\u09b9\\u09be\\u09b0\\u09bf\\u09df\\u09c7 \\u0995\\u09be\\u0981\\u09a6\\u099b\\u09c7 \\u098f\\u09ae\\u09aa\\u09bf \\u0993 \\u099c\\u09be\\u09ae\\u09be\\u0987\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_debiased\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u09e7\\u09e6 \\u09ac\\u099b\\u09b0\\u09c7\\u09b0 \\u09b8\\u09a8\\u09cd\\u09a4\\u09be\\u09a8 \\u09ab\\u09c7\\u09b2\\u09c7 \\u0986,\\u09b2\\u09c0\\u0997 \\u09a8\\u09c7\\u09a4\\u09be\\u09b0 \\u09b8\\u09be\\u09a5\\u09c7 \\u09aa\\u09be\\u09b2\\u09bf\\u09df\\u09c7 \\u0997\\u09c7\\u09b2 \\u098f\\u09ae\\u09aa\\u09bf\\u09b0 \\u09ae\\u09c7\\u09df\\u09c7! \\u09b8\\u09ac \\u09b9\\u09be\\u09b0\\u09bf\\u09df\\u09c7 \\u0995\\u09be\\u0981\\u09a6\\u099b\\u09c7 \\u098f\\u09ae\\u09aa\\u09bf \\u0993 \\u099c\\u09be\\u09ae\\u09be\\u0987\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u09ad\\u09bf\\u09a1\\u09bf\\u0993\\u099f\\u09bf \\u09ad\\u09be\\u09b2 \\u09b2\\u09be\\u0997\\u09b2\\u09c7 \\u09b2\\u09be\\u0987\\u0995 \\u09a6\\u09bf\\u09a8 \\r\\n\\u0993 \\u09b8\\u09ac\\u09be\\u0987\\u0995\\u09c7 \\u09a6\\u09c7\\u0996\\u09be\\u09b0 \\u09b8\\u09c1\\u09af\\u09cb\\u0997 \\u0995\\u09b0\\u09c7 \\u09a6\\u09bf\\u09a4\\u09c7 Share \\u09b6\\u09c7\\u09df\\u09be\\u09b0 \\u0995\\u09b0\\u09c1\\u09a8\\u0964\\r\\n\\r\\n\\u25b6 Thanks all for watching this video.\\r\\nadvanced thanks for \\u261eSubscribe\\u261c my channel.\\r\\n\\r\\n\\u25b6 Subscribe \\u09b2\\u09bf\\u0982\\u0995 : https://goo.gl/wqxP1R\\r\\n\\r\\n\\r\\nNotice: If anyone use this channel video, we will Claimed You and take action as YouTube copyright law.\\r\\n\\r\\n\\u0986\\u09ae\\u09be\\u09a6\\u09c7\\u09b0 \\u099a\\u09cd\\u09af\\u09be\\u09a8\\u09c7\\u09b2\\u09c7\\u09b0 \\u0995\\u09cb\\u09a8 \\u09ad\\u09bf\\u09a1\\u09bf\\u0993 \\u0985\\u09a8\\u09cd\\u09af \\u0995\\u09cb\\u09a8 \\u099a\\u09cd\\u09af\\u09be\\u09a8\\u09c7\\u09b2\\u09c7 \\u09aa\\u09be\\u0993\\u09af\\u09bc\\u09be \\u0997\\u09c7\\u09b2\\u09c7 \\u0995\\u09aa\\u09bf\\u09b0\\u09be\\u0987\\u099f \\u0995\\u09cd\\u09b2\\u09c7\\u0987\\u09ae \\u09a6\\u09c7\\u0993\\u09df\\u09be \\u09b9\\u09ac\\u09c7 \\u0993 \\u09a8\\u09bf\\u09af\\u09bc\\u09ae \\u0985\\u09a8\\u09c1\\u09b8\\u09be\\u09b0\\u09c7 \\u09ac\\u09cd\\u09af\\u09ac\\u09b8\\u09cd\\u09a5\\u09be \\u09a8\\u09c7\\u09af\\u09bc\\u09be \\u09b9\\u09ac\\u09c7 \\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_debiased\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u09ad\\u09bf\\u09a1\\u09bf\\u0993\\u099f\\u09bf \\u09b2\\u09be\\u0997\\u09b2\\u09c7 \\u09b2\\u09be\\u0987\\u0995 \\u09a6\\u09bf\\u09a8 \\u0993 \\u09b8\\u09ac\\u09be\\u0987\\u0995\\u09c7 \\u09a6\\u09c7\\u0996\\u09be\\u09b0 \\u09b8\\u09c1\\u09af\\u09cb\\u0997 \\u0995\\u09b0\\u09c7 \\u09a6\\u09bf\\u09a4\\u09c7 Share \\u09b6\\u09c7\\u09df\\u09be\\u09b0 \\u0995\\u09b0\\u09c1\\u09a8\\u0964 \\u25b6 Thanks all for watching this video. advanced thanks for \\u261eSubscribe\\u261c my channel. \\u25b6 Subscribe \\u09b2\\u09bf\\u0982\\u0995 : https://goo.gl/wqxP1R Notice: If anyone use this channel video, we will Claimed You take action as YouTube copyright law. \\u0986\\u09ae\\u09be\\u09a6\\u09c7\\u09b0 \\u099a\\u09cd\\u09af\\u09be\\u09a8\\u09c7\\u09b2\\u09c7\\u09b0 \\u0995\\u09cb\\u09a8 \\u09ad\\u09bf\\u09a1\\u09bf\\u0993 \\u0985\\u09a8\\u09cd\\u09af \\u0995\\u09cb\\u09a8 \\u099a\\u09cd\\u09af\\u09be\\u09a8\\u09c7\\u09b2\\u09c7 \\u09aa\\u09be\\u0993\\u09af\\u09bc\\u09be \\u0997\\u09c7\\u09b2\\u09c7 \\u0995\\u09aa\\u09bf\\u09b0\\u09be\\u0987\\u099f \\u0995\\u09cd\\u09b2\\u09c7\\u0987\\u09ae \\u09a6\\u09c7\\u0993\\u09df\\u09be \\u09b9\\u09ac\\u09c7 \\u0993 \\u09a8\\u09bf\\u09af\\u09bc\\u09ae \\u0985\\u09a8\\u09c1\\u09b8\\u09be\\u09b0\\u09c7 \\u09ac\\u09cd\\u09af\\u09ac\\u09b8\\u09cd\\u09a5\\u09be \\u09a8\\u09c7\\u09af\\u09bc\\u09be \\u09b9\\u09ac\\u09c7 \\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://www.youtube.com/watch?v=HPa6mRwjUg8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"viewCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39637,\n        \"min\": 12743,\n        \"max\": 114242,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          22440\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commentCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 10,\n        \"max\": 59,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"likeCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 383,\n        \"min\": 362,\n        \"max\": 1352,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dislikeCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 20,\n        \"max\": 122,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thumbnail\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://i.ytimg.com/vi/HPa6mRwjUg8/default.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auto_labeled\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Clickbait\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_labeled\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Clickbait\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ai_labeled\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Clickbait\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text columns present: ['title', 'title_debiased', 'description', 'description_debiased']\n",
            "Label columns present: ['auto_labeled', 'human_labeled', 'ai_labeled']\n",
            "\n",
            "Text columns: non-null count and sample lengths (first 3 non-null):\n",
            "  - title: 253070 non-null, sample length values (smallest) [17, 18, 19]\n",
            "  - title_debiased: 253070 non-null, sample length values (smallest) [15, 16, 17]\n",
            "  - description: 253070 non-null, sample length values (smallest) [48, 49, 51]\n",
            "  - description_debiased: 253070 non-null, sample length values (smallest) [48, 49, 50]\n",
            "\n",
            "--- Inspecting label column: auto_labeled ---\n",
            "dtype: object\n",
            "sample unique values (up to 20): ['Clickbait', 'Not Clickbait']\n",
            "value counts (top 10):\n",
            "auto_labeled\n",
            "Not Clickbait    223758\n",
            "Clickbait         29312\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Inspecting label column: human_labeled ---\n",
            "dtype: object\n",
            "sample unique values (up to 20): ['Clickbait', 'Not Clickbait']\n",
            "value counts (top 10):\n",
            "human_labeled\n",
            "None             243070\n",
            "Clickbait          5644\n",
            "Not Clickbait      4356\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Inspecting label column: ai_labeled ---\n",
            "dtype: object\n",
            "sample unique values (up to 20): ['Clickbait', 'Not Clickbait']\n",
            "value counts (top 10):\n",
            "ai_labeled\n",
            "Not Clickbait    208015\n",
            "Clickbait         45055\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label cross-tabs (pairwise):\n",
            "\n",
            "Cross-tab: auto_labeled vs human_labeled\n",
            "human_labeled  Clickbait  Not Clickbait    All\n",
            "auto_labeled                                  \n",
            "Clickbait           5644            160   5804\n",
            "Not Clickbait          0           4196   4196\n",
            "All                 5644           4356  10000\n",
            "\n",
            "Cross-tab: auto_labeled vs ai_labeled\n",
            "ai_labeled     Clickbait  Not Clickbait     All\n",
            "auto_labeled                                   \n",
            "Clickbait          23979           5333   29312\n",
            "Not Clickbait      21076         202682  223758\n",
            "All                45055         208015  253070\n",
            "\n",
            "Cross-tab: human_labeled vs ai_labeled\n",
            "ai_labeled     Clickbait  Not Clickbait    All\n",
            "human_labeled                                 \n",
            "Clickbait           5627             17   5644\n",
            "Not Clickbait         26           4330   4356\n",
            "All                 5653           4347  10000\n",
            "\n",
            "Saved first 200 rows to sample_first_200.csv (you can download from Colab sidebar).\n",
            "\n",
            "\n",
            "===== DONE: paste the printed outputs (or upload the sample CSV) and I'll provide the next step =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create frozen BanglaBERT embeddings, prepare features, train logistic regression across configs\n",
        "# Run in Google Colab (assumes df variable already loaded from Step 1)\n",
        "\n",
        "# Install deps\n",
        "!pip install -q transformers accelerate sentencepiece scikit-learn numpy pandas tqdm\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import joblib\n",
        "\n",
        "# ----------------- USER CONFIG -----------------\n",
        "# Choose a frozen Bangla encoder.\n",
        "#  - \"sagorsarker/bangla-bert-base\"  (BERT-base for Bangla). :contentReference[oaicite:1]{index=1}\n",
        "#  - \"csebuetnlp/banglabert\"        (BanglaBERT ELECTRA discriminator). :contentReference[oaicite:2]{index=2}\n",
        "model_name = \"csebuetnlp/banglabert\"\n",
        "# ------------------------------------------------\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# If df not defined (you can uncomment and set file_path)\n",
        "# file_path = 'your_dataset.parquet'\n",
        "# df = pd.read_parquet(file_path)\n",
        "\n",
        "# Ensure the columns we expect exist\n",
        "text_cols = ['title', 'title_debiased', 'description', 'description_debiased']\n",
        "present_text = [c for c in text_cols if c in df.columns]\n",
        "print(\"Text columns present:\", present_text)\n",
        "\n",
        "label_cols = [c for c in ['auto_labeled', 'human_labeled', 'ai_labeled'] if c in df.columns]\n",
        "print(\"Label columns present:\", label_cols)\n",
        "\n",
        "# ----------------- Embedding utilities -----------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    # model_output[0] is last_hidden_state: (batch, seq_len, hidden)\n",
        "    token_embeddings = model_output.last_hidden_state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = input_mask_expanded.sum(1).clamp(min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "def encode_texts(texts, batch_size=32, cache_path=None):\n",
        "    \"\"\"\n",
        "    texts: iterable/list of strings\n",
        "    returns: numpy array shape (len(texts), hidden_size)\n",
        "    Caches to cache_path if provided.\n",
        "    \"\"\"\n",
        "    if cache_path and os.path.exists(cache_path):\n",
        "        print(\"Loading embeddings from cache:\", cache_path)\n",
        "        return np.load(cache_path)[\"arr_0\"]\n",
        "    all_embs = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding batches\"):\n",
        "        batch_texts = [str(t) if pd.notna(t) else \"\" for t in texts[i:i+batch_size]]\n",
        "        encoded = tokenizer(batch_texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "        for k in encoded:\n",
        "            encoded[k] = encoded[k].to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(**encoded)\n",
        "            emb = mean_pooling(out, encoded[\"attention_mask\"])  # (batch, hidden)\n",
        "            emb = emb.cpu().numpy()\n",
        "        all_embs.append(emb)\n",
        "    all_embs = np.vstack(all_embs)\n",
        "    if cache_path:\n",
        "        np.savez_compressed(cache_path, all_embs)\n",
        "        print(\"Saved embeddings to\", cache_path)\n",
        "    return all_embs\n",
        "\n",
        "# ----------------- Prepare feature texts -----------------\n",
        "def safe_join(a, b):\n",
        "    if pd.isna(a) and pd.isna(b):\n",
        "        return \"\"\n",
        "    if pd.isna(a):\n",
        "        return str(b)\n",
        "    if pd.isna(b):\n",
        "        return str(a)\n",
        "    return str(a) + \" \" + str(b)\n",
        "\n",
        "configs = {}\n",
        "# single fields\n",
        "for c in present_text:\n",
        "    configs[c] = df[c].fillna(\"\").astype(str).tolist()\n",
        "# # concatenations\n",
        "# if 'title' in present_text and 'description' in present_text:\n",
        "#     configs['title__description'] = [safe_join(a,b) for a,b in zip(df['title'], df['description'])]\n",
        "# if 'title_debiased' in present_text and 'description_debiased' in present_text:\n",
        "#     configs['title_deb__description_deb'] = [safe_join(a,b) for a,b in zip(df['title_debiased'], df['description_debiased'])]\n",
        "\n",
        "print(\"Text configurations to embed:\", list(configs.keys()))\n",
        "\n",
        "# ----------------- Compute (or load cached) embeddings for each config -----------------\n",
        "os.makedirs(\"embeddings_cache\", exist_ok=True)\n",
        "embeddings = {}\n",
        "for name, texts in configs.items():\n",
        "    cache_file = f\"embeddings_cache/{name.replace('/','_')}_{model_name.replace('/','_')}.npz\"\n",
        "    # compute and cache\n",
        "    emb = encode_texts(texts, batch_size=32, cache_path=cache_file)\n",
        "    embeddings[name] = emb\n",
        "    print(f\"{name}: embeddings shape = {emb.shape}\")\n",
        "\n",
        "# ----------------- Label handling: auto-detect & binarize -----------------\n",
        "def make_binary_labels(series):\n",
        "    # series: pd.Series\n",
        "    ser = series.copy()\n",
        "    ser_name = ser.name\n",
        "    # If numeric and only 0/1 -> use as is\n",
        "    if pd.api.types.is_numeric_dtype(ser):\n",
        "        unique = np.unique(ser.dropna())\n",
        "        if set(unique).issubset({0,1}):\n",
        "            return ser.fillna(0).astype(int)\n",
        "        # If probabilities [0,1], threshold 0.5\n",
        "        if (ser.dropna() >= 0).all() and (ser.dropna() <= 1).all():\n",
        "            print(f\"Warning: {ser_name} looks like probabilities, thresholding at 0.5\")\n",
        "            return (ser.fillna(0) >= 0.5).astype(int)\n",
        "    # If boolean\n",
        "    if ser.dtype == 'bool':\n",
        "        return ser.fillna(False).astype(int)\n",
        "    # If strings: try common labels\n",
        "    str_vals = ser.dropna().astype(str).str.lower().unique()\n",
        "    # common positive keywords\n",
        "    pos_keys = {'clickbait','click-bait','click bait','yes','1','true','y','cb'}\n",
        "    neg_keys = {'not_clickbait','not-clickbait','not clickbait','not','no','0','false','n','non-cb','nonclickbait','non_clickbait'}\n",
        "    mapped = []\n",
        "    for v in ser.astype(str).fillna(\"nan\"):\n",
        "        vs = v.strip().lower()\n",
        "        if vs in pos_keys:\n",
        "            mapped.append(1)\n",
        "        elif vs in neg_keys:\n",
        "            mapped.append(0)\n",
        "        else:\n",
        "            # unable to confidently map -> treat as NaN for now\n",
        "            mapped.append(np.nan)\n",
        "    mapped = pd.Series(mapped, index=ser.index)\n",
        "    # If too many NaNs, fallback to LabelEncoder (will return integer classes)\n",
        "    if mapped.isna().mean() > 0.5:\n",
        "        print(f\"Label column {ser_name}: many unmapped textual values — using LabelEncoder fallback.\")\n",
        "        le = LabelEncoder()\n",
        "        filled = ser.fillna(\"MISSING\").astype(str)\n",
        "        return pd.Series(le.fit_transform(filled), index=ser.index)\n",
        "    else:\n",
        "        return mapped.fillna(0).astype(int)\n",
        "\n",
        "bin_labels = {}\n",
        "for lab in label_cols:\n",
        "    bin_labels[lab] = make_binary_labels(df[lab])\n",
        "    print(f\"{lab}: value counts ->\")\n",
        "    print(bin_labels[lab].value_counts(dropna=False))\n",
        "\n",
        "# ----------------- Training + evaluation across configs & labels -----------------\n",
        "results = []\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "for lab in label_cols:\n",
        "    y = bin_labels[lab].values\n",
        "    # Only keep rows where y is not NaN (shouldn't be after our mapping)\n",
        "    valid_idx = ~pd.isna(y)\n",
        "    if valid_idx.sum() == 0:\n",
        "        print(f\"Skipping {lab}: no valid labels after mapping.\")\n",
        "        continue\n",
        "    y = y[valid_idx].astype(int)\n",
        "    print(f\"\\n=== Label: {lab}  (n={len(y)}) ===\")\n",
        "    for cfg_name, X_full in embeddings.items():\n",
        "        X = X_full[valid_idx]\n",
        "        # standardize\n",
        "        scaler = StandardScaler()\n",
        "        Xs = scaler.fit_transform(X)\n",
        "        # train/test split (stratify when possible)\n",
        "        stratify = y if len(np.unique(y)) > 1 else None\n",
        "        X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2, random_state=42, stratify=stratify)\n",
        "        # logistic regression (liblinear for small samples; sag for larger)\n",
        "        solver = \"liblinear\" if X_train.shape[0] < 5000 else \"saga\"\n",
        "        clf = LogisticRegression(max_iter=1000, solver=solver)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        # probabilities for AUC if possible\n",
        "        try:\n",
        "            y_prob = clf.predict_proba(X_test)[:,1]\n",
        "            auc = roc_auc_score(y_test, y_prob)\n",
        "        except Exception:\n",
        "            auc = np.nan\n",
        "        res = {\n",
        "            \"label_col\": lab,\n",
        "            \"text_config\": cfg_name,\n",
        "            \"n_train\": X_train.shape[0],\n",
        "            \"n_test\": X_test.shape[0],\n",
        "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "            \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "            \"roc_auc\": auc\n",
        "        }\n",
        "        print(f\"{lab} | {cfg_name} -> acc {res['accuracy']:.3f} prec {res['precision']:.3f} rec {res['recall']:.3f} f1 {res['f1']:.3f} auc {res['roc_auc']}\")\n",
        "        results.append(res)\n",
        "        # Save model and scaler\n",
        "        model_fname = f\"models/logreg_{lab}_{cfg_name}.joblib\".replace(\"/\",\"_\")\n",
        "        joblib.dump({\"clf\": clf, \"scaler\": scaler, \"model_name\": model_name}, model_fname)\n",
        "\n",
        "# Save results\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"embedding_logreg_results.csv\", index=False)\n",
        "print(\"\\nSaved results to embedding_logreg_results.csv\")\n",
        "display(results_df.sort_values(['label_col','f1'], ascending=[True, False]).head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "8e45965b2aa44e32ac2cc019b2fa57a5",
            "504b9c4e13d9495c915d385d132960a5",
            "372937e26b4e4f9eb49b391d91a70e97",
            "9768bcf20a0e496e94b59ae8946d1d42",
            "bb56f242ebc44c75a05a522508825ec3",
            "10b6f6ceeaeb45c3be36419973aa22ca",
            "fdd2ba008fbb4a7a8a1ca623ddafb9d1",
            "3b885e1a01b44b14b5a3ac48315d8da4",
            "7aea96ef060d445fb6873ffe2681a657",
            "ad32bc934c204b19a8dd9a21de103e04",
            "484ae71619f84f768c2bfa33bf56654e"
          ]
        },
        "id": "yXoRO7lDhzua",
        "outputId": "f03f96d1-d32e-4ae6-ff94-4a50c50653a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Text columns present: ['title', 'title_debiased', 'description', 'description_debiased']\n",
            "Label columns present: ['auto_labeled', 'human_labeled', 'ai_labeled']\n",
            "Text configurations to embed: ['title', 'title_debiased', 'description', 'description_debiased']\n",
            "Loading embeddings from cache: embeddings_cache/title_csebuetnlp_banglabert.npz\n",
            "title: embeddings shape = (253070, 768)\n",
            "Loading embeddings from cache: embeddings_cache/title_debiased_csebuetnlp_banglabert.npz\n",
            "title_debiased: embeddings shape = (253070, 768)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding batches:   0%|          | 0/7909 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e45965b2aa44e32ac2cc019b2fa57a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Robust evaluation (Stratified K-Fold CV, confusion matrices, ROC/PR curves, optional bootstrap CIs)\n",
        "# Run in Google Colab (expects embeddings cached in embeddings_cache/ OR `embeddings` dict present)\n",
        "\n",
        "!pip install -q scikit-learn matplotlib seaborn numpy pandas joblib\n",
        "\n",
        "import os, glob, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "                             confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score)\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --------- User options ----------\n",
        "n_splits = 5\n",
        "random_state = 42\n",
        "compute_bootstrap = True   # set False to skip bootstrap CIs\n",
        "n_bootstrap = 1000\n",
        "bootstrap_sample_size = 0.8  # proportion of test sample for each bootstrap draw\n",
        "# ---------------------------------\n",
        "\n",
        "os.makedirs(\"cv_results\", exist_ok=True)\n",
        "os.makedirs(\"cv_plots\", exist_ok=True)\n",
        "\n",
        "# Try to reuse embeddings dict from session; otherwise load from cache files\n",
        "try:\n",
        "    embeddings  # if variable defined, use it\n",
        "except NameError:\n",
        "    embeddings = {}\n",
        "    # load any .npz files in embeddings_cache\n",
        "    files = sorted(glob.glob(\"embeddings_cache/*.npz\"))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(\"No `embeddings` variable and no embeddings_cache/*.npz found. Rerun Step 2 to produce embeddings.\")\n",
        "    for fpath in files:\n",
        "        name = os.path.basename(fpath).split(\".npz\")[0]\n",
        "        # tidy name: remove model postfix if present\n",
        "        name = name.replace(\"_\" + name.split(\"_\")[-1], \"\") if False else name\n",
        "        arr = np.load(fpath)[\"arr_0\"]\n",
        "        embeddings[name] = arr\n",
        "    print(\"Loaded embeddings:\", list(embeddings.keys()))\n",
        "\n",
        "# Load labels (bin_labels) if available in session, otherwise try to reconstruct from file 'sample_first_200.csv' or df\n",
        "try:\n",
        "    bin_labels\n",
        "except NameError:\n",
        "    # try to infer from df if present\n",
        "    try:\n",
        "        # use the same make_binary_labels logic as Step 2\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        def make_binary_labels(series):\n",
        "            ser = series.copy()\n",
        "            if pd.api.types.is_numeric_dtype(ser):\n",
        "                unique = np.unique(ser.dropna())\n",
        "                if set(unique).issubset({0,1}):\n",
        "                    return ser.fillna(0).astype(int)\n",
        "                if (ser.dropna() >= 0).all() and (ser.dropna() <= 1).all():\n",
        "                    return (ser.fillna(0) >= 0.5).astype(int)\n",
        "            if ser.dtype == 'bool':\n",
        "                return ser.fillna(False).astype(int)\n",
        "            str_vals = ser.dropna().astype(str).str.lower().unique()\n",
        "            pos_keys = {'clickbait','click-bait','click bait','yes','1','true','y','cb'}\n",
        "            neg_keys = {'not_clickbait','not-clickbait','not clickbait','not','no','0','false','n','non-cb','nonclickbait','non_clickbait'}\n",
        "            mapped = []\n",
        "            for v in ser.astype(str).fillna(\"nan\"):\n",
        "                vs = v.strip().lower()\n",
        "                if vs in pos_keys:\n",
        "                    mapped.append(1)\n",
        "                elif vs in neg_keys:\n",
        "                    mapped.append(0)\n",
        "                else:\n",
        "                    mapped.append(np.nan)\n",
        "            mapped = pd.Series(mapped, index=ser.index)\n",
        "            if mapped.isna().mean() > 0.5:\n",
        "                le = LabelEncoder()\n",
        "                filled = ser.fillna(\"MISSING\").astype(str)\n",
        "                return pd.Series(le.fit_transform(filled), index=ser.index)\n",
        "            else:\n",
        "                return mapped.fillna(0).astype(int)\n",
        "        # build bin_labels for available label columns in df\n",
        "        label_cols = [c for c in ['auto_labeled','human_labeled','ai_labeled'] if c in df.columns]\n",
        "        bin_labels = {lab: make_binary_labels(df[lab]) for lab in label_cols}\n",
        "        print(\"Reconstructed bin_labels for:\", list(bin_labels.keys()))\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Could not find `bin_labels` or construct from df. Ensure Step 2 ran and `bin_labels` variable exists.\") from e\n",
        "\n",
        "# Utility: compute metrics\n",
        "def compute_metrics(y_true, y_pred, y_prob=None):\n",
        "    m = {}\n",
        "    m['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    m['precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
        "    m['recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
        "    m['f1'] = f1_score(y_true, y_pred, zero_division=0)\n",
        "    if y_prob is not None and len(np.unique(y_true)) > 1:\n",
        "        try:\n",
        "            m['roc_auc'] = roc_auc_score(y_true, y_prob)\n",
        "        except Exception:\n",
        "            m['roc_auc'] = np.nan\n",
        "        try:\n",
        "            m['avg_precision'] = average_precision_score(y_true, y_prob)\n",
        "        except Exception:\n",
        "            m['avg_precision'] = np.nan\n",
        "    else:\n",
        "        m['roc_auc'] = np.nan\n",
        "        m['avg_precision'] = np.nan\n",
        "    return m\n",
        "\n",
        "# Main CV loop\n",
        "summary_rows = []\n",
        "detailed_rows = []  # store per-fold metrics\n",
        "plot_index = 0\n",
        "\n",
        "for lab, y_series in bin_labels.items():\n",
        "    print(f\"\\n==== Label: {lab} ====\")\n",
        "    label_name = lab\n",
        "    y_all = np.array(y_series)\n",
        "    valid_idx = ~pd.isna(y_all)\n",
        "    y_all = y_all[valid_idx].astype(int)\n",
        "    # if all labels same class, skip CV\n",
        "    if len(np.unique(y_all)) < 2:\n",
        "        print(f\"Skipping {lab}: only one class present after binarization.\")\n",
        "        continue\n",
        "\n",
        "    for cfg_name, X_full in embeddings.items():\n",
        "        X = X_full[valid_idx]\n",
        "        # standardize per CV fold (scaler inside fold)\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "        fold = 0\n",
        "\n",
        "        # containers for aggregating metrics & curves\n",
        "        metrics_list = []\n",
        "        cm_sum = np.zeros((2,2), dtype=int)\n",
        "        # For ROC/PR aggregation: collect interp TPR at fixed FPR grid\n",
        "        mean_fpr = np.linspace(0,1,200)\n",
        "        tprs = []\n",
        "        mean_recall = np.linspace(0,1,200)\n",
        "        precisions_interp = []\n",
        "\n",
        "        plt.figure(figsize=(6,5))\n",
        "        # ROC plot base\n",
        "        for train_idx, test_idx in skf.split(X, y_all):\n",
        "            fold += 1\n",
        "            X_train_raw, X_test_raw = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_train = scaler.fit_transform(X_train_raw)\n",
        "            X_test = scaler.transform(X_test_raw)\n",
        "\n",
        "            solver = \"liblinear\" if X_train.shape[0] < 5000 else \"saga\"\n",
        "            clf = LogisticRegression(max_iter=1000, solver=solver)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            try:\n",
        "                y_prob = clf.predict_proba(X_test)[:,1]\n",
        "            except Exception:\n",
        "                y_prob = None\n",
        "\n",
        "            # metrics\n",
        "            m = compute_metrics(y_test, y_pred, y_prob)\n",
        "            m['fold'] = fold\n",
        "            metrics_list.append(m)\n",
        "            detailed_row = {\n",
        "                \"label_col\": label_name, \"text_config\": cfg_name, \"fold\": fold,\n",
        "                **m\n",
        "            }\n",
        "            detailed_rows.append(detailed_row)\n",
        "\n",
        "            # confusion matrix\n",
        "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "            cm_sum += cm\n",
        "\n",
        "            # ROC curve points\n",
        "            if y_prob is not None:\n",
        "                fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "                # interpolate TPR at mean_fpr\n",
        "                tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
        "                tpr_interp[0] = 0.0\n",
        "                tprs.append(tpr_interp)\n",
        "                # precision-recall\n",
        "                precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "                # interp precision at fixed recall grid (monotonic decreasing recall -> reverse for interp)\n",
        "                # ensure recall is increasing for interpolation\n",
        "                recall_rev = recall[::-1]\n",
        "                precision_rev = precision[::-1]\n",
        "                prec_interp = np.interp(mean_recall, recall_rev, precision_rev, left=precision_rev[0], right=precision_rev[-1])\n",
        "                precisions_interp.append(prec_interp)\n",
        "\n",
        "        # aggregate metrics\n",
        "        metrics_df = pd.DataFrame(metrics_list)\n",
        "        agg = metrics_df[['accuracy','precision','recall','f1','roc_auc','avg_precision']].agg(['mean','std']).T\n",
        "        summary = {\n",
        "            \"label_col\": label_name,\n",
        "            \"text_config\": cfg_name,\n",
        "            \"n_folds\": n_splits,\n",
        "            \"n_samples\": len(y_all),\n",
        "            \"class_counts_0\": int((y_all==0).sum()),\n",
        "            \"class_counts_1\": int((y_all==1).sum()),\n",
        "            \"accuracy_mean\": agg.loc['accuracy','mean'],\n",
        "            \"accuracy_std\": agg.loc['accuracy','std'],\n",
        "            \"precision_mean\": agg.loc['precision','mean'],\n",
        "            \"precision_std\": agg.loc['precision','std'],\n",
        "            \"recall_mean\": agg.loc['recall','mean'],\n",
        "            \"recall_std\": agg.loc['recall','std'],\n",
        "            \"f1_mean\": agg.loc['f1','mean'],\n",
        "            \"f1_std\": agg.loc['f1','std'],\n",
        "            \"roc_auc_mean\": agg.loc['roc_auc','mean'] if not np.isnan(agg.loc['roc_auc','mean']) else np.nan,\n",
        "            \"roc_auc_std\": agg.loc['roc_auc','std'] if not np.isnan(agg.loc['roc_auc','std']) else np.nan,\n",
        "            \"avg_precision_mean\": agg.loc['avg_precision','mean'] if not np.isnan(agg.loc['avg_precision','mean']) else np.nan,\n",
        "            \"avg_precision_std\": agg.loc['avg_precision','std'] if not np.isnan(agg.loc['avg_precision','std']) else np.nan\n",
        "        }\n",
        "        summary_rows.append(summary)\n",
        "\n",
        "        # Save confusion matrix heatmap\n",
        "        cm_df = pd.DataFrame(cm_sum, index=[\"pred_0?\",\"pred_1?\"], columns=[\"true_0\",\"true_1\"])\n",
        "        plt.figure(figsize=(4,3))\n",
        "        sns.heatmap(cm_sum, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"true_0\",\"true_1\"], yticklabels=[\"pred_0\",\"pred_1\"])\n",
        "        plt.title(f\"Confusion Matrix: {label_name} | {cfg_name}\")\n",
        "        cm_path = f\"cv_plots/cm_{label_name}_{cfg_name}.png\".replace(\"/\",\"_\")\n",
        "        plt.savefig(cm_path, bbox_inches=\"tight\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "        # Plot mean ROC curve across folds\n",
        "        if tprs:\n",
        "            mean_tpr = np.mean(tprs, axis=0)\n",
        "            mean_tpr[-1] = 1.0\n",
        "            mean_auc = auc(mean_fpr, mean_tpr)\n",
        "            std_tpr = np.std(tprs, axis=0)\n",
        "\n",
        "            plt.figure(figsize=(6,5))\n",
        "            plt.plot(mean_fpr, mean_tpr, lw=2, label=f\"Mean ROC (AUC = {mean_auc:.3f})\")\n",
        "            tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "            tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "            plt.fill_between(mean_fpr, tpr_lower, tpr_upper, alpha=0.2, label=\"±1 std\")\n",
        "            plt.plot([0,1],[0,1], linestyle=\"--\", lw=1)\n",
        "            plt.xlabel(\"False Positive Rate\")\n",
        "            plt.ylabel(\"True Positive Rate\")\n",
        "            plt.title(f\"ROC: {label_name} | {cfg_name}\")\n",
        "            plt.legend(loc=\"lower right\")\n",
        "            roc_path = f\"cv_plots/roc_{label_name}_{cfg_name}.png\".replace(\"/\",\"_\")\n",
        "            plt.savefig(roc_path, bbox_inches=\"tight\", dpi=150)\n",
        "            plt.close()\n",
        "        else:\n",
        "            roc_path = None\n",
        "\n",
        "        # Plot mean PR curve across folds\n",
        "        if precisions_interp:\n",
        "            mean_prec = np.mean(precisions_interp, axis=0)\n",
        "            std_prec = np.std(precisions_interp, axis=0)\n",
        "            mean_ap = np.nanmean([r['avg_precision'] for r in metrics_list if not np.isnan(r['avg_precision'])])\n",
        "            plt.figure(figsize=(6,5))\n",
        "            plt.plot(mean_recall, mean_prec, lw=2, label=f\"Mean PR (AP ≈ {mean_ap:.3f})\")\n",
        "            prec_upper = np.minimum(mean_prec + std_prec, 1)\n",
        "            prec_lower = np.maximum(mean_prec - std_prec, 0)\n",
        "            plt.fill_between(mean_recall, prec_lower, prec_upper, alpha=0.2)\n",
        "            plt.xlabel(\"Recall\")\n",
        "            plt.ylabel(\"Precision\")\n",
        "            plt.title(f\"Precision-Recall: {label_name} | {cfg_name}\")\n",
        "            plt.legend(loc=\"upper right\")\n",
        "            pr_path = f\"cv_plots/pr_{label_name}_{cfg_name}.png\".replace(\"/\",\"_\")\n",
        "            plt.savefig(pr_path, bbox_inches=\"tight\", dpi=150)\n",
        "            plt.close()\n",
        "        else:\n",
        "            pr_path = None\n",
        "\n",
        "        # Optional bootstrap CI for F1: aggregate across folds by combining test sets?\n",
        "        # We'll bootstrap within each fold's test predictions to estimate CI of F1 for that fold, then pool.\n",
        "        if compute_bootstrap:\n",
        "            # For reproducible bootstrap, re-run one train/test split per fold and keep predictions\n",
        "            # We'll gather all test predictions by re-training on full dataset with KFold splits and storing per-fold predictions\n",
        "            boot_f1s = []\n",
        "            for train_idx, test_idx in skf.split(X, y_all):\n",
        "                X_train_raw, X_test_raw = X[train_idx], X[test_idx]\n",
        "                y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
        "                scaler = StandardScaler()\n",
        "                X_train = scaler.fit_transform(X_train_raw)\n",
        "                X_test = scaler.transform(X_test_raw)\n",
        "                solver = \"liblinear\" if X_train.shape[0] < 5000 else \"saga\"\n",
        "                clf = LogisticRegression(max_iter=1000, solver=solver)\n",
        "                clf.fit(X_train, y_train)\n",
        "                try:\n",
        "                    y_prob = clf.predict_proba(X_test)[:,1]\n",
        "                except Exception:\n",
        "                    y_prob = None\n",
        "                y_pred = clf.predict(X_test)\n",
        "                # now bootstrap over test indices\n",
        "                for _ in range(n_bootstrap // n_splits):\n",
        "                    # sample indices with replacement from test set\n",
        "                    m = max(1, int(len(test_idx) * bootstrap_sample_size))\n",
        "                    sample_idx = np.random.choice(len(test_idx), size=m, replace=True)\n",
        "                    y_s = y_test[sample_idx]\n",
        "                    y_p = y_pred[sample_idx]\n",
        "                    boot_f1s.append(f1_score(y_s, y_p, zero_division=0))\n",
        "            if len(boot_f1s) > 0:\n",
        "                lo = np.percentile(boot_f1s, 2.5)\n",
        "                hi = np.percentile(boot_f1s, 97.5)\n",
        "            else:\n",
        "                lo, hi = (np.nan, np.nan)\n",
        "        else:\n",
        "            lo, hi = (np.nan, np.nan)\n",
        "\n",
        "        # record summary, include paths to plots\n",
        "        summary.update({\n",
        "            \"confusion_matrix_path\": cm_path,\n",
        "            \"roc_plot_path\": roc_path,\n",
        "            \"pr_plot_path\": pr_path,\n",
        "            \"f1_bootstrap_2.5pct\": lo,\n",
        "            \"f1_bootstrap_97.5pct\": hi\n",
        "        })\n",
        "        # Save detailed per-fold metrics to CSV for this pair\n",
        "        pair_df = pd.DataFrame([r for r in detailed_rows if r['label_col']==label_name and r['text_config']==cfg_name])\n",
        "        if pair_df.shape[0] > 0:\n",
        "            pair_csv = f\"cv_results/{label_name}__{cfg_name}__folds.csv\".replace(\"/\",\"_\")\n",
        "            pair_df.to_csv(pair_csv, index=False)\n",
        "        # Add to summary file\n",
        "        # (we append later after loop)\n",
        "\n",
        "# Save summary and detailed CSVs\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(\"cv_results_summary.csv\", index=False)\n",
        "detailed_df = pd.DataFrame(detailed_rows)\n",
        "detailed_df.to_csv(\"cv_results_detailed.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved summary CSV: cv_results_summary.csv\")\n",
        "print(\"Saved detailed fold metrics: cv_results_detailed.csv\")\n",
        "print(\"Saved confusion matrices and curves under cv_plots/ and per-pair folds under cv_results/\")\n",
        "\n",
        "# Show top results by f1_mean\n",
        "if not summary_df.empty:\n",
        "    display(summary_df.sort_values(\"f1_mean\", ascending=False).head(20))\n"
      ],
      "metadata": {
        "id": "RBPtnecwvjPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}